---
title: API Reference

language_tabs: # must be one of https://git.io/vQNgJ
  - python

toc_footers:
#  - <a href='#'>Sign Up for a Developer Key</a>
#  - <a href='https://github.com/lord/slate'>Documentation Powered by Slate</a>

includes:
#  - errors

search: true
---

<%= image_tag "images/rocketbase-illustration.jpg" %>
# Introduction

Welcome to the Rocketbase.ai. Here you will find everything you need to know about rockets :)

# Getting Started with Rocketbase
This guide shows you how to install and run Rockets using Rocketbase. 


## Installation

> Run the following code as a python script to check your installation. 

```python
from rockethub import Rocket
model = Rocket.land('igor/esrgan')
print('Success!')
```

> The script should return `Sucess` if everything worked.

Rocketbase works with Python 3.6+ and is built on the PyTorch deep learning framework.

To install rocketbase you must [install PIP](https://pip.pypa.io/en/stable/installing/), the python package manager, first.

Now you can install the rocketbase PIP package using the following command in your terminal:

`pip install rocketbase`

### Test your Rocketbase installation

To test whether your installation was successful you can simply try to run the code we provide on the right.

## What are Rockets?

> A simple Rocket for image superresolution:

```python
from rockethub import Rocket
from PIL import Image

img = Image.open('cat.png')

model = Rocket.land('igor/esrgan').eval()
with torch.no_grad():
  img_tensor = model.preprocess(img)
  out = model(img_tensor)
img_out = model.postprocess(out)
```

A Rocket is a standardized and independent deep learning model. 
On Rocketbase.ai you will find already built and pretrained Rockets for the most common use cases in computer vision. 

Each Rocket belongs to a rocketfamily such as object detection, image recognition, style transfer etc.

<aside class="notice">
You must install the rocketbase PIP package first to run the examples
</aside>

## Why is this new?

There are existing places where you will find pretrained models. But usually, you end up either receiving just a frozen graph
or a whole github repository. A graph is super lightweight, it's just a binary file with weights and modules. But unfortunately
they are not very handy for use cases where you need to adapt that model. For example, if you need want to retrain the 
model using transfer learning a graph comes a bit unhandy. It appears like a big chunk of black box with some layers
and weights in a not human readable format. 

Using Github repositories helps a lot since you have access to all the layers, all the training code and and and. There
we have already the problem with those repositories. They are often super complex and with lots of code. Understanding what
happenes where, getting it to running to use a model can take quite some time. Based on a survey it takes more than 20%
of the time of top people in machine learning industry and academia.


***Todo...***

| | Tensorflow Hub | Rocketbase | 
|--|-----------------|----------|
|Pretrained Image Recognition Models| Yes | Yes |


Rockets combine the pros of both, just a simple frozen graph and the full repository. You get access to all the layers as 
in the repository. Additionally, we provide simple helper methods to pre- and postprocess data. 

All this allows you to use any Rocket with just a few lines of code.


## What is part of a Rocket?

> Usually, working with Rockets consists of four parts. First, we need to land the Rocket:

```python
model = Rocket.land('igor/esrgan')
```

> Now, we need to prepare the input data such that we can use PyTorch:

```python
input_tensor = model.preprocess(input_data)
```

> After preprocessing the input we can run the Rocket:

```python
out_tensor = model(input_tensor)
```

> Finally, we want to convert the raw output into a standardized output format:

```python
output_data = model.postprocess(out_tensor)
```

In order to simplify deep learning workflows we separate the model from the code. To make the model reusable as simple as possible we package them into so called Rockets. 

As you can see in the following illustration a Rocket contains more than just the model. We also include functionality for data pre- and postprocessing. Some Rockets which are marked as retrainable also include the the loss function. 

<%= image_tag "images/rocket-parts-illustration.png" %>


* A Rocket always contains the `code to build a deep learning model`
* Methods for pre- and postprocessing of data
* File containing the `pretrained weights`
* They have a unique identifier the so called `Rocket Slug`
* Information about the origin of the Rocket `info.json`


<aside class="notice">
Every Rocket comes with pretrained weights but not all Rockets are retrainable
</aside>

## Swapping a Model example

> Rockets can easily be swapped out by changing the rocket slug

```python
# this code uses yolov3 for object detection
model = Rocket.land('lucas/yolov3')

# and this code uses retinanet for object detection
model = Rocket.land('igor/retinanet')
```

For example, we can swap out Rockets with a single line of code. This might sound very simple. But in fact this is something unusual in deep learning. Usually, a code base is linked with one or more models. 

This allows us also to work on the deep learning model separately from the code base. The code you write can also be used for all Rockets from the same rocket family without any change. 

<aside class="success">
Remember - Rockets within the same family can always be swapped out
</aside>


## Code once, use everywhere

> Using a Rocket on different devices

```python
# automatically run on GPU if available, otherwise CPU
model = Rocket.land('lucas/yolov3')

# run on CPU
model = Rocket.land('lucas/yolov3', device='CPU')

# run on GPU
model = Rocket.land('lucas/yolov3', device='GPU')

# run via API (you get the api url from the rocketbase.ai platform)
model = Rocket.land('lucas/yolov3', device='API')

```

The standardization of a Rocket allows you to run any Rocket on a CPU or GPU. The only dependency is that the PyTorch framework has to run on the device. 

But how about running a Rocket on a less powerful device without a GPU, like a raspberry pi?

Just add `API` as the `device` parameter of the `Rocket.land(..)` method. Your code will automatically use the Rocket via an API provided by rocketbase.ai

The input and output of behavior the same Rocket should always match, no matter on which device you run it. This gives you a lot of additional freedom while prototyping. 

Building a deep learning prototype on a macbook and later sharing it with a friend who has a powerful GPU without any extra work suddenly becomes very easy.

<aside class="success">
Remember - Rockets run on different hardware devices and be exposed as an API
</aside>

## Benchmarking Rockets example

> You can use the following code to benchmark 3 different object detection Rockets in terms of processing time

```python

# create our list of Rockets
models = []
models.append([Rocket.land('lucas/yolov3'), 'yolov3'])
models.append([Rocket.land('igor/ssd'), 'ssd'])
models.append([Rocket.land('igor/retinanet'), 'retinanet'])

for model, name in models:

  # track the processing time
  start_time = time.time()

  # now we can process some images with the same code
  img_tensor = model.preprocess(input_image)
  out_tensor = model(img_tensor)
  list_of_bboxes = model.postprocess(out_tensor)

  # calculate the processing time
  processing_time = time.time() - start_time

  print(f'Running Rocket {name} took {processing_time:.2f} seconds')
```

Rockets allow for simpler workflows for benchmarking or replacing existing deep learning models. A Rocket can always be replaced by any other Rocket from within the same Rocket family without any extra work.

A similar approach can be taken to find the optimal model based on your data. You can train different Rockets on the same dataset without rewriting the whole code.


# Rocket Families
To further support the standardization process we group Rockets into so called rocket families. A rocket family always shares the same input/ output interface. In this section we introduce you to the different rocket families and provide you some additional information on how to use the Rockets.

## Object Detection

Detecting objects in images or videos is a very common task in computer vision. To help you out solving object detection problems we provide state-of-the-art models packaged in Rockets.

**Input and Output**

Rockets in this family work on images. The image will automatically be resized so you don't have to worry about that. The `postprocess` method also requires the input image as additional input. We use the input image for resizing the bounding boxes to the right size and for the optional visualization.

|input of preprocess|output of postprocess|
|--------|------------|
|`PIL.Image` | `list` of dictionaries with elements <br>[{`topLeft_x`, `topLeft_y`, `width`, `height`, `bbox_confidence`, `class_name`, `class_confidence`},...]|

<%= image_tag "images/object-detection-illustration.png" %>

Additionally, we provide a simple way to visualize the output detections by setting the `visualize` flag in `postprocess` to True.

<%= image_tag "images/object-detection-visualize-illustration.png" %>

<aside class="notice">
Object detection Rockets support visualization of the results by setting `visualize=True` in the postprocess method
</aside>

### Counting Cups in an Image using Rockets

> Count cups in an image using a Rocket

```python
from PIL import Image
from rockethub import Rocket

# load an image using PIL
image_path = 'image_with_cups.jpg'
img = Image.open(image_path).convert('RGB')

# land a rocket
rocket = 'lucas/yolov3'
model = Rocket.land(rocket).eval()

# process the image with our rocket
with torch.no_grad():
    img_tensor = model.preprocess(img)
    out = model(img_tensor)
    bboxes_out = model.postprocess(out, img)

# create a counter to keep track of the cups
cup_counter = 0

# loop through all objects detected and count cups
for bbox in bboxes_out:
  x, y, w, h, bbox_conf, class_name, class_conf = bbox
  if class_name == 'cup':
    cup_counter += 1

print(f'The image contains {cup_counter} cups.')
```

To show how we can use an object recognition Rocket we want to build a python script to count the amount of cups in an image. Think about a shared kitchen and we want to keep track how many cups are in the kitchen sink instead of the dishwasher.

**Here are the parts we need:** 

* load input image
* a Rocket which can detect cups
* a mechanism to count the amount of cups
* print output




## Superresolution

Turning a low resolution image into HD sounds like science fiction. But using a Rocket this can be done with just a few lines of code.

**Input and Output**

Rockets in this family work with images. This Rocket works fairly simple.

|input of preprocess|output of postprocess|
|--------|------------|
|`PIL.Image` | `PIL.Image`|


<%= image_tag "images/superresolution-illustration.png" %>


### Selfie Improver using Rockets

> Improve picture quality using a Rocket

```python
from PIL import Image
from rockethub import Rocket

# load an image using PIL
image_path = 'selfie.png'
img = Image.open(image_path).convert('RGB')

# land a rocket
rocket = 'igor/esrgan'
model = Rocket.land(rocket).eval()

# process the image with our rocket
with torch.no_grad():
    img_tensor = model.preprocess(img)
    out = model(img_tensor)
    img_out = model.postprocess(out, img)

# save high definition image
img_out.save('selfie_HD.png')
```

In this example we will create a `selfie booster` or simply just a python script to improve quality of an image.

**Here are the parts we need:** 

* load input image
* a Rocket which can do superresolution
* save output image

You will notice, that superresolution Rockets have images as both, input and output. 

## Image Recognition

**Input and Output**

Rockets in this family work with images. The output is always a list of dictionaries containing confidence score and class label sorted by confidence.

|input of preprocess|output of postprocess|
|--------|------------|
|`PIL.Image` | `list` of dictionaries with elements <br>[{`class_name`, `class_confidence`},...]|

### Picture Sorting using Rockets

> Sorting pictures using image recognition Rockets

```python
import os
import shutil
from glob import glob
from PIL import Image
from rockethub import Rocket

# get a list of all .jpg images inside input_folder
list_of_imgs = glob('input_folder/*.jpg')

# land a rocket
rocket = 'momo/resnet34'
model = Rocket.land(rocket).eval()

# loop through the images
for fname in list_of_imgs:
  img = Image.open(image_path).convert('RGB')

  with torch.no_grad():
    img_tensor = model.preprocess(img)
    out = model(img_tensor)
    img_out = model.postprocess(out, img)
  
  # get class name with highest confidence
  class_name = img_out[0]['class_name']

  # check if folder for this class exists
  if not os.path.exists(dir_name):
    os.makedirs(dir_name)

  # copy original picture into new folder
  dst_fname = os.path.basename(fname)
  dst_fname = os.path.join(class_name, dst_fname)
  shutil.copyfile(fname, dst_fname)
```

Let's create a script which takes all pictures from a folder and sorts them into subfolders according to the content. We want pictures of cats to be in the `cat` folder and pictures of cars to be in the `car` folder.


## Image Segmentation

**Input and Output**

> Class confidence values sum up to `1.0`

```python
...
model = Rocket.land('lucas/deeplabv2')

with torch.no_grad():
  out_tensor = model(input_tensor)
  out = model.postprocess(out_tensor)

# check sum of out for a pixel
coord = [0,0]
sum = 0.0

# loop through confidences at position coord and sum up
for elem in out:
  sum += elem['class_confidence_2d_array']

print(f'Sum at position {coord} is {sum}')
```

Image Segmentation Rockets use single Images as input. The output is a list of dictionaries containing a `class_name` and a `class_confidence_2d_array`. Together they allow you to get probabilities for each pixel in the input image to be part of a certain class.


The `class_confidence_2d_array` is a numpy array containing values between `0.0` and `1.0` indicating the confidence. The class confidences of a specific input pixel sum up to `1.0`. 

|input of preprocess|output of postprocess|
|--------|------------|
|`PIL.Image` | `list` of dictionaries with elements <br>[{`class_name`, `class_confidence_2d_array`},...]|


### Bokeh effect using Rockets

In this example we want to create a so called `bokeh` effect as used by the newer iPhones and Skype for example. To goal is simply to blur the background of an image.

> Bokeh effect using Rockets

```python
from PIL import Image, ImageFilter
from rockethub import Rocket

# load an image using PIL
image_path = 'selfie.png'
img = Image.open(image_path).convert('RGB')

# land a rocket
rocket = 'lucas/deeplabv2'
model = Rocket.land(rocket).eval()

# process the image with our rocket
with torch.no_grad():
    img_tensor = model.preprocess(img)
    out = model(img_tensor)
    output_tensor = model.postprocess(out, img)

# get the mask for person
for elem in output_tensor:
  if elem['class_name'] == 'Person':
    mask = elem['class_confidence_2d_array']
    break

# threshold mask
mask[mask > 0.5] = 1.0
mask[mask < 1.0] = 0.0
mask = mask.astype(np.uint8)

# separate input image in foreground/ background
img_np = np.asarray(img)
fg = img_np[mask]
bg = img_np[1-mask]

# blur background
bg = Image.fromarray(bg)
bg = bg.filter(ImageFilter.GaussianBlur(15))

# stich together image
fg = np.asarray(fg)
bg = np.asarray(bg)

img = fg[mask] + bg[1-mask]
img = Image.fromarray(img)

# save bokeh image
img.save('selfie_bokeh.png')
```

## Pose Estimation

***Todo..***



## Style Transfer

***Todo..***


# Build your Own Rocket

***Todo..***
