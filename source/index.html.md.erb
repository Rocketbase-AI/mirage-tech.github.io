---
title: API Reference

language_tabs: # must be one of https://git.io/vQNgJ
  - python

toc_footers:
#  - <a href='#'>Sign Up for a Developer Key</a>
#  - <a href='https://github.com/lord/slate'>Documentation Powered by Slate</a>

includes:
#  - errors

search: true
---

<%= image_tag "images/rocketbase-illustration.jpg" %>
# Introduction

Welcome to **Rocketbase.ai**. 
Here you will find everything you need to know about Rockets :)

# Getting Started with Rocketbase
This guide shows you how to install and run Rockets using Rocketbase. 


***Coming soon:***

* *Transfer learning with Rockets*
* *Using Rockets on iOS and Android*

## The rocketbase PIP package
To easy access and management of Rockets we provide a python PIP package. The package provides you very useful methods to `land` and `launch` Rockets.

### Landing a Rocket

> A rocket can be loaded using the `Rocket Slug`

```python
model = Rocket.land('username/modelName')
```

To use a Rocket you need to land it first. This can be done easily by using the PIP package and the desired `Rocket Slug`, a unique identifier of each Rocket. Think of it as the GitHub repository URL. 

The land method has two parameters, first you need to define the `Rocket Slug` to land a specific Rocket. The second parameter is optional and can be used to select the `device` on which the Rocket should run. Rockets can be run on three different devices: `CPU`, `GPU` and `API`.


### Launching a Rocket
At some point you might want to modify the landed Rocket or even create your own Rocket. You can push your new Rocket to the rocketbase.ai platform by using the launch functionality of the PIP package.

> A rocket can be launched using the `Rocket Slug`

```python
liftoff = Rocket.launch('username/modelName/<hash>')
```

To launch a rocket, you can simply use this line in the same Python file as for the previous snippet.

<aside class="notice">
Don't forget to replace <b>username/modelName</b> with the slug of the desired Rocket
</aside>

## Installation
The rocketbase python package works with `Python 3.6+` and is built on the `PyTorch` deep learning framework.

To install rocketbase you must [install PIP](https://pip.pypa.io/en/stable/installing/), the python package manager, first.

Now you can install the rocketbase PIP package using the following command in your terminal:

`pip install rocketbase`

### Test your Rocketbase installation

> Run the following code as a python script to check your installation. 

```python
from rocketbase import Rocket
model = Rocket.land('igor/esrgan')
print('Success!')
```

> The script should return `Sucess` if everything worked.

To test whether your installation was successful you can simply try to run the code we provide on the right.


## What are Rockets?

> A simple Rocket for image superresolution:

```python
from rocketbase import Rocket
from PIL import Image

img = Image.open('cat.png')

model = Rocket.land('igor/esrgan').eval()
with torch.no_grad():
  img_tensor = model.preprocess(img)
  out = model(img_tensor)
img_out = model.postprocess(out)
```

A Rocket is a standardized and independent deep learning model. 
On Rocketbase.ai you will find already built and pretrained Rockets for the most common use cases in computer vision. 

Each Rocket belongs to a rocketfamily such as object detection, image classification, style transfer etc.

<aside class="notice">
You must install the rocketbase PIP package first to run the examples
</aside>


## What is part of a Rocket?

> Usually, working with Rockets consists of four parts. First, we need to land the Rocket:

```python
model = Rocket.land('igor/esrgan')
```

> Now, we need to prepare the input data such that we can use PyTorch:

```python
input_tensor = model.preprocess(input_data)
```

> After preprocessing the input we can run the Rocket:

```python
out_tensor = model(input_tensor)
```

> Finally, we want to convert the raw output into a standardized output format:

```python
output_data = model.postprocess(out_tensor)
```

In order to simplify deep learning workflows we separate the model from the code. To make reusing the model as simple as possible, they are packaged into so called Rockets. 

As you can see in the following illustration a Rocket contains more than just the model. We also include functionality for data pre- and postprocessing. Some Rockets which are marked as retrainable also include the necessary components to retrain (e.g. loss function). 

<%= image_tag "images/rocket-parts-illustration.png" %>

**A Rocket always contains:**

* The `code to build a deep learning model`
* Methods for pre- and postprocessing of data
* File containing the `pretrained weights`
* Information about the origin of the Rocket `info.json`

Every Rocket has is identified by its unique identifier, the so called `Rocket Slug`


<aside class="notice">
Every Rocket comes with pretrained weights but not all Rockets are retrainable
</aside>

## Swapping a Model example

> Rockets can easily be swapped out by changing the Rocket slug

```python
# this code uses yolov3 for object detection
model = Rocket.land('lucas/yolov3')

# and this code uses retinanet for object detection
model = Rocket.land('igor/retinanet')
```

For example, we can swap out Rockets with a single line of code. This might sound trivial, but in fact this is something unusual in deep learning. Usually, a code base is linked with one or more models. 

This also allows us to work on the deep learning model separately from the code base. The code you write can also be used for all Rockets from the same rocket family without any change. 

<aside class="success">
Remember - Rockets within the same family can always be swapped out
</aside>


## Code once, use everywhere

> Using a Rocket on different devices

```python
# automatically run on GPU if available, otherwise CPU
model = Rocket.land('lucas/yolov3')

# run on CPU
model = Rocket.land('lucas/yolov3', device='CPU')

# run on GPU
model = Rocket.land('lucas/yolov3', device='GPU')

# run via API (you get the api url from the Rocketbase.ai platform)
model = Rocket.land('lucas/yolov3', device='API')

```

The standardization of a Rocket allows you to run any Rocket on a CPU or GPU. The only dependency is that the PyTorch framework has to run on the device. 

But how about running a Rocket on a less powerful device without a GPU, like a RaspberryPi?

Just add `API` as the `device` parameter of the `Rocket.land(..)` method. Your code will automatically use the Rocket via an API provided by Rocketbase.ai

The input and output of the same Rocket should always match, no matter on which device you run it. This gives you a lot of additional freedom while prototyping. 

Building a deep learning prototype on a Macbook and later sharing it with a friend who has a powerful GPU without any extra work suddenly becomes very easy.

<aside class="success">
Remember - Rockets can run on different hardware devices and be exposed as an API
</aside>


### Example: Launch your new Rocket

> Launch Rocket

```python

from rocketbase import Rocket

liftoff = Rocket.launch('username/modelName/<hash>')

print("Rocket successfully launched! Houston, no problemo" if liftoff else "Houston we have a problem")

```

Launching a Rocket to rocketbase.ai is as simple as landing one. Simply import the package and use the launch function.
This script (launch.py) should be located next to your `rockets` folder:

* My-app :
  * rockets
  * launch.py
  * ...


<aside class="notice">
We are currently working on a simple CLI interface to make this even simpler. Coming soon...
</aside>


## Benchmarking Rockets example

> You can use the following code to benchmark 3 different object detection Rockets in terms of processing time

```python

# create our list of Rockets
models = []
models.append([Rocket.land('lucas/yolov3'), 'yolov3'])
models.append([Rocket.land('igor/ssd'), 'ssd'])
models.append([Rocket.land('igor/retinanet'), 'retinanet'])

for model, name in models:

  # do a `dry` run to make sure we have proper benchmarking results
  img_tensor = model.preprocess(input_image)
  out_tensor = model(img_tensor)
  list_of_bboxes = model.postprocess(out_tensor)

  # track the processing time
  start_time = time.time()

  # now we can process some images with the same code
  img_tensor = model.preprocess(input_image)
  out_tensor = model(img_tensor)
  list_of_bboxes = model.postprocess(out_tensor)

  # calculate the processing time
  processing_time = time.time() - start_time

  print(f'Running Rocket {name} took {processing_time:.2f} seconds')
```

Rockets allow for simpler workflows for benchmarking or replacing existing deep learning models. A Rocket can always be replaced by any other Rocket from the same Rocket family without any extra work.

For the example on the left we obtain the following numbers for inference time:

|Rocket Name|CPU|GPU|
|----|---|---|
|lucas/yolov3|99.9s|99.9s|
|igor/ssd|99.9s|99.9s|
|igor/retinanet|99.9s|99.9s|

*Note that we are only benchmarking the runtime and not the accuracy of the rockets*

A similar approach can be taken to find the optimal model based on your data. You can train different Rockets on the same dataset without rewriting the whole code.


# Rocket Families
To further support the standardization process we group Rockets into so called Rocket families. A Rocket family always shares the same input/output interface. In this section we introduce you to the different rocket families and provide you some additional information on how to use the Rockets.


## Image Object Detection

Detecting objects in images or videos is a very common task in computer vision. To help you out in object detection problems we provide state-of-the-art models packaged in Rockets.

**Input and Output**

Rockets in this family work on images. The image will automatically be resized so you don't have to worry about that. The `postprocess` method also requires the input image as additional input. We use the input image for resizing the bounding boxes to the right size and for the optional visualization.

|input of preprocess|output of postprocess|
|--------|------------|
|`PIL.Image` | `list` of dictionaries with elements <br>[{`topLeft_x`, `topLeft_y`, `width`, `height`, `bbox_confidence`, `class_name`, `class_confidence`},...]|

<%= image_tag "images/object-detection-illustration.png" %>

Additionally, we provide a simple way to visualize the output detections by setting the `visualize` flag in `postprocess` to True.

<%= image_tag "images/object-detection-visualize-illustration.png" %>

<aside class="notice">
Object detection Rockets support visualization of the results by setting `visualize=True` in the postprocess method
</aside>

### Counting Cups in an Image using Rockets

> Count cups in an image using a Rocket

```python
from PIL import Image
from rocketbase import Rocket

# load an image using PIL
image_path = 'image_with_cups.jpg'
img = Image.open(image_path).convert('RGB')

# land a rocket
rocket = 'lucas/yolov3'
model = Rocket.land(rocket).eval()

# process the image with our rocket
with torch.no_grad():
    img_tensor = model.preprocess(img)
    out = model(img_tensor)
    bboxes_out = model.postprocess(out, img)

# create a counter to keep track of the cups
cup_counter = 0

# loop through all objects detected and count cups
for bbox in bboxes_out:
  x, y, w, h, bbox_conf, class_name, class_conf = bbox
  if class_name == 'cup':
    cup_counter += 1

print(f'The image contains {cup_counter} cups.')
```

To show how we can use an object detection Rocket we want to build a python script to count the amount of cups in an image. Think about a shared kitchen and we want to keep track of how many cups are in the kitchen sink instead of the dishwasher.

**Here are the parts we need:** 

* load input image
* a Rocket which can detect cups
* a mechanism to count the amount of cups
* print output




## Image Superresolution

Turning a low resolution image into HD sounds like science fiction. But using a Rocket, this can be done with just a few lines of code.

**Input and Output**

Rockets in this family work with images.

|input of preprocess|output of postprocess|
|--------|------------|
|`PIL.Image` | `PIL.Image`|


<%= image_tag "images/superresolution-illustration.png" %>


### Selfie Enhancer using Rockets

> Improve picture quality using a Rocket

```python
from PIL import Image
from rocketbase import Rocket

# load an image using PIL
image_path = 'selfie.png'
img = Image.open(image_path).convert('RGB')

# land a Rocket
rocket = 'igor/esrgan'
model = Rocket.land(rocket).eval()

# process the image with our Rocket
with torch.no_grad():
    img_tensor = model.preprocess(img)
    out = model(img_tensor)
    img_out = model.postprocess(out, img)

# save high definition image
img_out.save('selfie_HD.png')
```

In this example we will create a `selfie enhancer` or simply a python script to improve quality of an image.

**Here are the parts we need:** 

* load input image
* a Rocket which can do superresolution
* save output image

You will notice, that superresolution Rockets have images as both, input and output. 

## Image Classification

**Input and Output**

Rockets in this family work with images. The output is always a list of dictionaries containing confidence score and class label sorted by confidence.

|input of preprocess|output of postprocess|
|--------|------------|
|`PIL.Image` | `list` of dictionaries with elements <br>[{`class_name`, `class_confidence`},...]|

### Picture Sorting using Rockets

> Sorting pictures using image classification Rockets

```python
import os
import shutil
from glob import glob
from PIL import Image
from rocketbase import Rocket

# get a list of all .jpg images inside input_folder
list_of_imgs = glob('input_folder/*.jpg')

# land a rocket
rocket = 'momo/resnet34'
model = Rocket.land(rocket).eval()

# loop through the images
for fname in list_of_imgs:
  img = Image.open(image_path).convert('RGB')

  with torch.no_grad():
    img_tensor = model.preprocess(img)
    out = model(img_tensor)
    img_out = model.postprocess(out, img)
  
  # get class name with highest confidence
  class_name = img_out[0]['class_name']

  # check if folder for this class exists
  if not os.path.exists(dir_name):
    os.makedirs(dir_name)

  # copy original picture into new folder
  dst_fname = os.path.basename(fname)
  dst_fname = os.path.join(class_name, dst_fname)
  shutil.copyfile(fname, dst_fname)
```

Let's create a script which takes all pictures from a folder and sorts them into subfolders according to the content. We want pictures of cats to be in the `cat` folder and pictures of cars to be in the `car` folder.

<%= image_tag "images/picture-sorting-illustration.png" %>



## Image Segmentation

**Input and Output**

> Class confidence values sum up to `1.0`

```python
...
model = Rocket.land('lucas/deeplabv2')

with torch.no_grad():
  out_tensor = model(input_tensor)
  out = model.postprocess(out_tensor)

# check sum of out for a pixel
coord = [0,0]
sum = 0.0

# loop through confidences at position coord and sum up
for elem in out:
  sum += elem['class_confidence_2d_array']

print(f'Sum at position {coord} is {sum}')
```

Image Segmentation Rockets use single images as input. The output is a list of dictionaries containing a `class_name` and a `class_confidence_2d_array`. Together they allow you to get probabilities for each pixel in the input image to be part of a certain class.


The `class_confidence_2d_array` is a numpy array containing values between `0.0` and `1.0` indicating the confidence. The class confidences of a specific input pixel sum up to `1.0`. 

|input of preprocess|output of postprocess|
|--------|------------|
|`PIL.Image` | `list` of dictionaries with elements <br>[{`class_name`, `class_confidence_2d_array`},...]|


### Bokeh effect using Rockets

> Bokeh effect using Rockets

```python
from PIL import Image, ImageFilter
from rocketbase import Rocket

# load an image using PIL
image_path = 'selfie.png'
img = Image.open(image_path).convert('RGB')

# land a rocket
rocket = 'lucas/deeplabv2'
model = Rocket.land(rocket).eval()

# process the image with our rocket
with torch.no_grad():
    img_tensor = model.preprocess(img)
    out = model(img_tensor)
    output_tensor = model.postprocess(out, img)

# get the mask for person
for elem in output_tensor:
  if elem['class_name'] == 'Person':
    mask = elem['class_confidence_2d_array']
    break

# threshold mask
mask[mask > 0.5] = 1.0
mask[mask < 1.0] = 0.0
mask = mask.astype(np.uint8)

# separate input image in foreground/ background
img_np = np.asarray(img)
fg = img_np[mask]
bg = img_np[1-mask]

# blur background
bg = Image.fromarray(bg)
bg = bg.filter(ImageFilter.GaussianBlur(15))

# stich together image
fg = np.asarray(fg)
bg = np.asarray(bg)

img = fg[mask] + bg[1-mask]
img = Image.fromarray(img)

# save bokeh image
img.save('selfie_bokeh.png')
```

In this example we want to create a so called `bokeh` effect as used by the newer smartphones and video chats. The goal is simply to blur the background of an image. We can do this by using a Rocket to get the segmentation mask of the person in foreground (for simplicity we assume only one person in the image). Once we have obtained this mask we can use it to add blur to the part of the image not containing the person which mostly will be the background of the image.

<%= image_tag "images/bokeh-effect-illustration.png" %>

## Image Human Pose Estimation

In pose estimation we try to predict the pose of an entity in a scene. A typical use case is the prediction of the human body pose in an image. Pose estimation can be used for various use cases such as recognizing what a person currently is doing. 

**Input and Output**
Pose estimation Rockets use a single Image as input and return a list of found human poses in an image. By default the Rocket returns you a list of joints after post processing. You can also set the `visualize=True` flag to get more visual feedback which is especially useful for debugging.

|input of preprocess|output of postprocess|
|--------|------------|
|`PIL.Image` | `list` |



## Image Style Transfer


Image Style transfer Rockets can be used to transfer the style of an input `image A` to match the style of `image B`. The type of style varies depending on the specific Rocket. A style transformation can range from a simple color transformation up to replacing complete faces.

**Input and Output**
Image Style transfer Rockets have a quite simple input and output interface. Both input and output are images.

|input of preprocess|output of postprocess|
|--------|------------|
|`PIL.Image` | `PIL.Image` |

### Turning Summer into Winter

> Turn summer into winter using Rockets

```python
from PIL import Image
from rocketbase import Rocket

# load an image using PIL
image_path = 'summer-image.png'
img = Image.open(image_path).convert('RGB')

# land a Rocket
rocket = 'igor/cycle_gan_summer2winter_yosemite'
model = Rocket.land(rocket).eval()

# process the image with our Rocket
with torch.no_grad():
    img_tensor = model.preprocess(img)
    out = model(img_tensor)
    img_out = model.postprocess(out, img)

# save the winter image
img_out.save('winter.png')
```

Here we show you the result of using `cyclegan-summer2winter-yosemite` to transfer images from summer to look like images from winter.
<%= image_tag "images/style-transfer-illustration.png" %>